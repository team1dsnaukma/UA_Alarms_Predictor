{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7835f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import regex as re\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab175e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector_preprocessing(text, stop_words: list):\n",
    "    if not stop_words:\n",
    "        stop_words = stopwords.words(\"english\")\n",
    "    stemmer = PorterStemmer()\n",
    "    text_array = word_tokenize(re.sub('[\\W\\s\\d]', ' ', text.lower()))\n",
    "    processed_text = ' '.join(\n",
    "            [\n",
    "            stemmer.stem(word) for word in text_array\n",
    "            if (len(word) > 2) and (word not in stop_words)\n",
    "            ])\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def tfidf_vectorization(_corpus):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(_corpus)\n",
    "    sparse_matrix = pd.DataFrame(\n",
    "        X.todense(),\n",
    "        columns=vectorizer.get_feature_names())\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84430cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare all data for predict\n",
    "PATH_TO_MODULES = 'files_for_prediction'\n",
    "DATA_FOLDER = \"files_for_prediction/data\"\n",
    "sys.path.append(PATH_TO_MODULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38e62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features' data\n",
    "from get_info_from_api import get_all_regions_info_and_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32666c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_regions_info_and_prepare(DATA_FOLDER).to_csv(DATA_FOLDER + \"/features_for_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb34e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "features = pd.read_csv(DATA_FOLDER + \"/features_for_prediction.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d810d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "files_for_prediction\\isw_parse.py:145: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['main_text'] = data['main_text'].str.replace(text, '')\n",
      "files_for_prediction\\isw_parse.py:169: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['main_text'] = data['main_text'].str.replace(text, '')\n",
      "files_for_prediction\\isw_parse.py:188: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['main_text'] = data['main_text'].str.replace(text, '')\n"
     ]
    }
   ],
   "source": [
    "# get ISW data for last day  \n",
    "from isw_parse import parser, writer, clean_data\n",
    "DIR_ISW = DATA_FOLDER + \"/isw_for_last_day.csv\"\n",
    "date = datetime.now().date() - timedelta(days=1)\n",
    "start_date, end_date = date, date\n",
    "parsed = parser(start_date, end_date)\n",
    "writer(parsed, DIR_ISW)\n",
    "clean_data(DIR_ISW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "583746b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast import forecast_all_regions\n",
    "\n",
    "with open(PATH_TO_MODULES + '/token.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "TOKEN = data.get('token', None)\n",
    "\n",
    "utc_time = datetime.utcnow()\n",
    "forecast_all_regions(TOKEN, DATA_FOLDER, utc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adeb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "isw_last_day = pd.read_csv(DATA_FOLDER + \"/isw_for_last_day.csv\")\n",
    "tg_12h = pd.read_csv(DATA_FOLDER + \"/messages_today.csv\")\n",
    "weather_data = pd.read_csv(DATA_FOLDER + \"/forecast_next_12_hours_all_regions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b60394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(weather_data[\"hour_datetimeEpoch\"], unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11bdff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "langs = ['english', 'russian']\n",
    "stop_words = ['russian'] + list(map(lambda elem: elem.lower(), calendar.month_name))[1:]\n",
    "for lang in langs:\n",
    "    stop_words += stopwords.words(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbb6d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing isw for last day\n",
    "processed_isw = isw_last_day[\"main_text\"].apply(\n",
    "    lambda row: to_vector_preprocessing(row, stop_words)\n",
    ")\n",
    "isw_vectorized = tfidf_vectorization(processed_isw.tolist())\n",
    "\n",
    "# processing tg messages for last 12 hours\n",
    "processed_tg = tg_12h['message'].apply(\n",
    "    lambda row: to_vector_preprocessing(row, stop_words)\n",
    ")\n",
    "tg_vectorized = tfidf_vectorization(processed_tg.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64fc2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle data inappropriates\n",
    "tg_vectorized[['date', 'time']] = tg_12h[['date', 'time']]\n",
    "isw_vectorized[\"date\"] = pd.to_datetime(isw_last_day[\"date\"], format='%d-%m-%Y')\n",
    "tg_vectorized[\"date\"] = pd.to_datetime(tg_12h[\"date\"], format='%Y-%m-%d')\n",
    "tg_vectorized[\"time\"] = pd.to_datetime(tg_12h[\"time\"], format='%H:%M:%S').dt.round('H')\n",
    "merged_sm = isw_vectorized.merge(tg_vectorized, how='outer', on=\"date\")\n",
    "merged_sm.drop(\"time_y\", axis=1, inplace=True)\n",
    "merged_sm = merged_sm.fillna(0)\n",
    "merged_sm = merged_sm.groupby(\"date\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c42e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "new = pca.fit_transform(merged_sm)\n",
    "merged_sm_2 = pd.DataFrame(new)\n",
    "merged_sm_2['date'] = merged_sm.index\n",
    "merged_sm_2[\"date\"] += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc37f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cols = [\n",
    "    'city_address', 'hour_datetimeEpoch', 'day_datetime', 'day_tempmax', \n",
    "    'day_tempmin', 'day_temp', 'day_dew', 'day_humidity', 'day_precip', 'day_precipcover',\n",
    "    'day_solarradiation', 'day_solarenergy', 'day_uvindex', 'day_moonphase',\n",
    "    'hour_temp', 'hour_humidity', 'hour_precip', 'hour_precipprob',\n",
    "    'hour_windgust', 'hour_windspeed', 'hour_winddir', 'hour_pressure',\n",
    "    'hour_visibility', 'hour_cloudcover', 'hour_solarradiation',\n",
    "    'hour_uvindex', 'hour_severerisk', 'hour_conditions'\n",
    "]\n",
    "weather_final = weather_data[weather_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a681a89a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zorian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weather_final[\"day_datetime\"] = pd.to_datetime(weather_final[\"day_datetime\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39d5c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_predict = weather_final.merge(merged_sm_2, left_on=\"day_datetime\", right_on=\"date\")\n",
    "data_for_predict[\"hour_datetime\"] = pd.to_datetime(data_for_predict[\"hour_datetimeEpoch\"], unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6896423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 336 is the number of columns after PCA for sparse matrix in final_data \n",
    "for i in range(2, 336):\n",
    "    data_for_predict[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866973e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"date\"] = pd.to_datetime(features[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eda4ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_for_predict.merge(features, how=\"left\", left_on=[\"hour_datetime\", \"city_address\"], right_on=[\"date\", \"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99bda5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_change = preprocessing.LabelEncoder()\n",
    "data[\"hour_conditions\"] = cond_change.fit_transform(data[\"hour_conditions\"])\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "data = pd.get_dummies(data, columns=['city_address'], prefix=\"\", prefix_sep=\"\")\n",
    "data.drop([\"city\", \"Сімферополь\", \"Луганськ\", 'date_x', 'date_y',\n",
    "           'hour_datetimeEpoch', \"day_datetime\"], axis=1, inplace=True)\n",
    "data.set_index(\"hour_datetime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "815435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "data.to_csv(DATA_FOLDER + \"/final_data_for_predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b05866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"..\\models\\trained_models\\1_logistic_reg_v2.pkl\", 'rb') as m: \n",
    "    log_reg = pickle.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaaeaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.columns.tolist)\n",
    "scaler=StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "test_data = pd.DataFrame(scaled_data, index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40ca98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_data.iloc[:, 366:].idxmax(axis=1), columns=[\"city\"])\n",
    "test[\"predict\"] = log_reg.predict(test_data).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "665ac489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-21 20:00:00</th>\n",
       "      <td>Дніпро</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-21 20:00:00</th>\n",
       "      <td>Запоріжжя</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-21 20:00:00</th>\n",
       "      <td>Миколаїв</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-21 20:00:00</th>\n",
       "      <td>Харків</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-21 21:00:00</th>\n",
       "      <td>Харків</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-21 22:00:00</th>\n",
       "      <td>Харків</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          city  predict\n",
       "hour_datetime                          \n",
       "2024-04-21 20:00:00     Дніпро        1\n",
       "2024-04-21 20:00:00  Запоріжжя        1\n",
       "2024-04-21 20:00:00   Миколаїв        1\n",
       "2024-04-21 20:00:00     Харків        1\n",
       "2024-04-21 21:00:00     Харків        1\n",
       "2024-04-21 22:00:00     Харків        1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"predict\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc0d3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv(\"predict_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
